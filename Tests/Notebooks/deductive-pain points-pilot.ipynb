{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba8d7ff-eb77-4326-8b5b-886ef960ce65",
   "metadata": {},
   "source": [
    "Guide: sections split by algorithm type (NLP (that aren't purely text embedders), LLM, text embedding), sub-sections are the particular model, sub-sub-sections is 1 for getting the scores and 2 for evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27559786-fc98-416e-bb0c-00d2eccd1a5b",
   "metadata": {},
   "source": [
    "**0) PILOT DATA SETUP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae7df1e-0b70-44c3-ad5d-0c7416d2ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "['cutting wood', 'didnâ€™t know how to use lathe', 'Finding drill', 'Taking out trash', 'Finding clamp', 'Loosening the lathe', 'Cleaning up after others', 'Too small of wood scraps.', 'Had to take trash out.', 'Had to find a clamp.', 'Had to dig in unlabeled container for a 12v drill.', 'Got bumped while using sander, accidentally pressed emergency stop button.', 'Had to clean off messy workspace.', 'People putting garbage in the scrp bin', 'People not throwing trash properly ripping the bag', 'People not putting things where they go', 'People not putting things back the way they were found', 'People leaving a mess and not cleaning up', 'bumped by person using belt sander', 'garbage bag had hole', 'sawdust left on machine', 'lathe chuck tightened too tight', 'only found 18V drill which was too big', 'Someone pushed them ', 'Finding clamps', 'Loosening the chuck', 'people squeezing by and caused him to restart', 'finding a drill', 'clearing the scrap bin', 'Height of miter saw', 'Trash in the scrap bin', 'Ripped Trash bag', 'Epoxy', 'Clamp unavailable', 'Drill Unavailable ', 'Lathe was dirty', 'Accidental emergency stop', 'Equipment not put away properly', 'People in the way while using power tools', 'Difficulty finding certain tools', 'Couldnt find proper equipment (gloves)', 'She was bumped into', 'The lathe was left covered in saw dust', 'The 18V drill was too big for her', 'The miter saw was too tall for her', 'The clamps were not put away']\n",
      "46\n",
      "['8', '0', '9', '10', '9', '1', '6', '8', '0', '5', '9', '7', '6', '0', '10', '5', '5', '6', '7', '10', '6', '1', '2', '7', '5', '1', '7', '9', '8', '4', '0', '10', '11', '5', '9', '6', '7', '5', '7', '9', '3', '7', '6', '2', '4', '5']\n",
      "['Lathe chuck overtightend', '18 V Drills too large to use with one hand', 'Disposable gloves are a large size', 'Miter saw is on tall table (awkward to use)', 'People forget to put away the clamps', 'Someone left sawdust and wood chips everywhere', 'Someone squeezed through aisle and bumped user (bumped e-stop)', 'Wood scraps too small to be useful', 'Digging through the unlabeled cabinets looking for drill', 'Trash bag is ripped', 'Had to wait for epoxy to cure']\n"
     ]
    }
   ],
   "source": [
    "raw_data = open(\"Pain point pilot data- ground truth.txt\", \"r\") \n",
    "data = raw_data.read() \n",
    "\n",
    "data_list = data.split(\"\\t\") \n",
    "#print(data_list) #if u wanna compare raw to the testable data\n",
    "\n",
    "#remove extra characters\n",
    "for string in data_list:\n",
    "    if \"\\n\" in string:\n",
    "        new_string = string.replace(\"\\n\", \"\")\n",
    "        #print(string)\n",
    "        i = data_list.index(string)\n",
    "        data_list[i] = new_string\n",
    "    if '\"' in string:\n",
    "        new_string = string.replace('\"', \"\")\n",
    "        i = data_list.index(string)\n",
    "        data_list[i] = new_string\n",
    "\n",
    "#print(data_list) \n",
    "raw_data.close() \n",
    "\n",
    "testable_data = []\n",
    "ground_truths = []\n",
    "count = 0\n",
    "for string in data_list:\n",
    "    if (len(string) > 2):\n",
    "        testable_data.append(string)\n",
    "        count += 1\n",
    "    elif (len(string) > 0):\n",
    "        ground_truths.append(string)\n",
    "\n",
    "print(len(testable_data)) #for reference\n",
    "print(testable_data)\n",
    "print(len(ground_truths))\n",
    "print(ground_truths)\n",
    "\n",
    "codes = [\"Lathe chuck overtightend\", \"18 V Drills too large to use with one hand\", \"Disposable gloves are a large size\", \"Miter saw is on tall table (awkward to use)\", \"People forget to put away the clamps\", \"Someone left sawdust and wood chips everywhere\", \"Someone squeezed through aisle and bumped user (bumped e-stop)\", \"Wood scraps too small to be useful\", \"Digging through the unlabeled cabinets looking for drill\", \"Trash bag is ripped\", \"Had to wait for epoxy to cure\"]\n",
    "print(codes) #for reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da1214b-3a6e-47a3-a19b-9d1969eb4149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['TD', 'text'],\n",
      "    num_rows: 46\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#process into a dataset \n",
    "from datasets import Dataset\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "data_numbers = []\n",
    "for i in range(len(testable_data)):\n",
    "     data_numbers.append(i)\n",
    "\n",
    "data = {\n",
    "    'TD': data_numbers,\n",
    "    'text': testable_data\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc46711-2b27-49c0-b41c-ce41142da2cc",
   "metadata": {},
   "source": [
    "\n",
    "**1.1.1) NLP (BART thematic analysis)** (https://huggingface.co/facebook/bart-large-mnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5431dc0-7b89-4fc8-8a4e-6de69cd8f547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "#model set-up\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c1d84-d80f-474b-bc85-34edd0c3a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "with open('output-BART.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    for i in range(5): \n",
    "        print(\"\\n\")\n",
    "        print(\"DATA: \" + testable_data[i] + \"\\n\")\n",
    "        #sequence_to_classify = testable_data[i]\n",
    "        sequence_to_classify = KeyDataset(dataset, \"text\")[i]\n",
    "        for code in codes:\n",
    "            candidate_labels = code\n",
    "            results = classifier(sequence_to_classify, candidate_labels, multi_label=False) #should I keep multi_labels=True? (whats the diff)\n",
    "            print(str(results[\"scores\"][0]) + \"\\t\" + code) #only gimme the scores\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6619e2b-7be5-4a53-a642-981fd262923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Finding drill', 'labels': ['practice', 'Screwdriver', 'look', 'hammer', 'cat'], 'scores': [0.8722097277641296, 0.0930788442492485, 0.017568174749612808, 0.00991278886795044, 0.0072304424829781055]}\n"
     ]
    }
   ],
   "source": [
    "#testing w/ shorter codes\n",
    "sequence_to_classify = \"Finding drill\"\n",
    "candidate_labels = [\"Screwdriver\", \"cat\", \"hammer\", \"look\", \"practice\"]\n",
    "results = classifier(sequence_to_classify, candidate_labels, multi_label=False) #should I keep multi_labels=True? (whats the diff)\n",
    "print(results)\n",
    "\n",
    "#try homonyms w/ other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3adc38-9e54-435b-b64a-1b49a741f7fa",
   "metadata": {},
   "source": [
    "**1.1.2) BART evaluation w/ confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8feede9c-91c8-4f9c-9b66-cbd76b477125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '8', '9', '3', '1', '1', '3', '8', '6', '4', '9', '11', '6', '8', '10', '5', '10', '6', '2', '10', '1', '1', '2', '7', '2', '8', '7', '9', '8', '4', '8', '10', '11', '8', '11', '6', '7', '11', '5', '9', '3', '7', '6', '2', '4', '5']\n",
      "['8', '0', '9', '10', '9', '1', '6', '8', '0', '5', '9', '7', '6', '0', '10', '5', '5', '6', '7', '10', '6', '1', '2', '7', '5', '1', '7', '9', '8', '4', '0', '10', '11', '5', '9', '6', '7', '5', '7', '9', '3', '7', '6', '2', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "#model set-up\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(testable_data)): \n",
    "    max_score = 0;\n",
    "    idx_of_max = 0;\n",
    "    #sequence_to_classify = testable_data[i]\n",
    "    sequence_to_classify = KeyDataset(dataset, \"text\")[i]\n",
    "    for j in range(len(codes)):\n",
    "        candidate_labels = codes[j]\n",
    "        results = classifier(sequence_to_classify, candidate_labels, multi_label=False) #should I keep multi_labels=True? (whats the diff)\n",
    "        if (results[\"scores\"][0] > max_score):\n",
    "            idx_of_max = j+1\n",
    "            max_score = results[\"scores\"][0]\n",
    "    predictions.append(idx_of_max)\n",
    "\n",
    "predictions_str = []\n",
    "for pred in predictions:\n",
    "    str_pred = str(pred)\n",
    "    predictions_str.append(str_pred)\n",
    "print((predictions_str))\n",
    "print((ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec227d60-e653-40fc-8bd5-b8f6f81db5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 0 3 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 2 0 0 1 0 1 1]\n",
      " [0 1 0 1 0 0 4 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 4 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 4 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "[0.         0.5        0.75       0.4        0.66666667 0.5\n",
      " 0.8        0.4        0.72727273 0.72727273 0.4        0.8       ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(confusion_matrix(ground_truths, predictions_str, labels=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\"]))\n",
    "BART_eval = f1_score(ground_truths, predictions_str, average=None) \n",
    "print(BART_eval)\n",
    "#check what we wanna do for the average parameter (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c9be8-ae7a-439e-a1c4-3ea3a2504172",
   "metadata": {},
   "source": [
    "**1.2.1) BERT sentence similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be2601-95e4-46b7-a15d-927c57efc292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread IPythonHistorySavingThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\IPython\\core\\history.py\", line 853, in writeout_cache\n",
      "    self._writeout_input_cache(conn)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\IPython\\core\\history.py\", line 836, in _writeout_input_cache\n",
      "    conn.execute(\"INSERT INTO history VALUES (?, ?, ?, ?)\",\n",
      "sqlite3.IntegrityError: UNIQUE constraint failed: history.session, history.line\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\IPython\\core\\history.py\", line 908, in run\n",
      "    self.history_manager.writeout_cache(self.db)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\decorator.py\", line 232, in fun\n",
      "    return caller(func, *(extras + args), **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\IPython\\core\\history.py\", line 61, in only_when_enabled\n",
      "    return f(self, *a, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\IPython\\core\\history.py\", line 856, in writeout_cache\n",
      "    print(\"ERROR! Session/line number was not unique in\",\n",
      "ValueError: I/O operation on closed file.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\decorator.py\", line 232, in fun\n",
      "    return caller(func, *(extras + args), **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\IPython\\core\\history.py\", line 61, in only_when_enabled\n",
      "    return f(self, *a, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\IPython\\core\\history.py\", line 910, in run\n",
      "    print((\"The history saving thread hit an unexpected error (%s).\"\n",
      "ValueError: I/O operation on closed file.\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001C4C8F8C5E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "No sentence-transformers model found with name tomaarsen/static-similarity-mrl-multilingual-v1. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download from the ðŸ¤— Hub\n",
    "model = SentenceTransformer(\"tomaarsen/static-similarity-mrl-multilingual-v1\")\n",
    "# Run inference\n",
    "sentences = [\n",
    "    'It is known for its dry red chili powder .',\n",
    "    'It is popular for dry red chili powder .',\n",
    "    'These monsters will move in large groups .',\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 1024]\n",
    "\n",
    "# Get the similarity scores for the embeddings\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)\n",
    "# [3, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ab1f2-25c9-416e-b6a0-dcf4ef6f29d6",
   "metadata": {},
   "source": [
    "**2.1) LLM: Microsoft Phi** (https://huggingface.co/microsoft/Phi-4-mini-instruct)\n",
    "- it works fine on a singular case, just loses efficiency when it has to rerun every time.\n",
    "- can be fixed with datasets (?), so GPU is optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfd073d6-7089-4f0a-9f79-a2ed616f4fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b729046e3b140378c0437cf69117bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': [{'role': 'user', 'content': \"calculate the percent similarity between 'Finding drill' and 'drill'. Don't tell me how, just give me the percent similarity.\"}, {'role': 'assistant', 'content': \"The percent similarity between 'Finding drill' and 'drill' is approximately 83.33%.\"}]}]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"calculate the percent similarity between 'Finding drill' and 'drill'. Don't tell me how, just give me the percent similarity.\"}\n",
    "]\n",
    "pipe = pipeline(\"text-generation\", model=\"microsoft/Phi-4-mini-instruct\", trust_remote_code=True)\n",
    "print(pipe(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de67bc3-e4f0-4d3d-9242-1a5ff63a7297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a00b926f5b420ba084bc4acb6a3f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DATA: cutting wood\n",
      "\n",
      "The percent similarity between cutting wood and a lathe chuck overtightened is approximately 0%. These\n",
      "The percent similarity between cutting wood and 18 V drills too large to use with one hand is approximately\n",
      "0%\n",
      "The percent similarity between cutting wood and using a miter saw on a tall table (awkward to\n",
      "The percent similarity between cutting wood and people forgetting to put away clamps is approximately 0%. These activities\n",
      "The percent similarity between cutting wood and someone leaving sawdust and wood chips everywhere is approximately 95%.\n",
      "The percent similarity between cutting wood and someone squeezing through an aisle and bumping an e-stop is approximately\n",
      "Approximately 95%\n",
      "The percent similarity between cutting wood and digging through unlabeled cabinets looking for a drill is approximately 25\n",
      "The percent similarity between cutting wood and a trash bag being ripped is approximately 0%. These actions are\n",
      "The percent similarity between cutting wood and having to wait for epoxy to cure is approximately 25%.\n",
      "\n",
      "\n",
      "DATA: didnâ€™t know how to use lathe\n",
      "\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"Lathe chuck overt\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"18 V Drills\n",
      "0%\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"Miter saw is\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"People forget to put\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"Someone left sawdust\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"Someone squeezed through aisle\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"wood scraps too small\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"digging through the\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"trash bag is ripped\n",
      "The percent similarity between \"didn't know how to use lathe\" and \"had to wait for\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "import sys\n",
    "\n",
    "\n",
    "#original_stdout = sys.stdout\n",
    "#with open('output.txt', 'w') as f:\n",
    "#    sys.stdout = f\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"microsoft/Phi-4-mini-instruct\", trust_remote_code=True)\n",
    "for i in range(2): \n",
    "    print(\"\\n\")\n",
    "    print(\"DATA: \" + testable_data[i] + \"\\n\")\n",
    "    for code in codes:\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": \"calculate the percent similarity between \" + KeyDataset(dataset, \"text\")[i] + \" and \" + code + \". Don't tell me how, just give me the percent similarity.\"}\n",
    "        ] \n",
    "        result = pipe(messages)\n",
    "        print(result[0][\"generated_text\"][1][\"content\"])\n",
    "\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbcf40db-bf4d-440c-8e24-d5f988061ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aeee1fb77c14afcaf2bb5402f442d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': [{'role': 'user', 'content': \"Is there any similarity between 'Finding drill' and 'drill'? If so, tell me the percent similarity.\"}, {'role': 'assistant', 'content': 'The words \"Finding drill\" and \"drill\" share some similarities, but they are not identical'}]}]\n"
     ]
    }
   ],
   "source": [
    "# trying a yes/no prompt\n",
    "from transformers import pipeline\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Is there any similarity between 'Finding drill' and 'drill'? If so, tell me the percent similarity.\"}\n",
    "]\n",
    "pipe = pipeline(\"text-generation\", model=\"microsoft/Phi-4-mini-instruct\", trust_remote_code=True)\n",
    "print(pipe(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768983d-059c-404c-a1ca-f1721979693b",
   "metadata": {},
   "source": [
    "**2.2) LLM: Meta Llama**\n",
    "- need to refine prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c843f8-a35b-458b-8c20-f4e34cb2c9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68344c0fc6b54c98af977fd3b25f92e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2a898f-dc00-4784-9784-e061b93eb935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DATA: cutting wood\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot verify the percent similarity between cutting wood and lathe chuck overtightened.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't provide a percentage similarity between cutting wood and using 18V drills too large for one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn't find any information that suggests cutting wood and using large disposable gloves are similar. However,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd estimate the percent similarity between cutting wood and using a Miter saw on a tall table to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn't find any information on a topic called \"cutting wood\" and \"People forget to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent similarity is approximately 75%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've calculated the percent similarity between the two phrases. The result is approximately 0.00%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent similarity between cutting wood and wood scraps too small to be useful is approximately 60%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the tasks you've described, I would estimate the percent similarity between cutting wood and digging through\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent similarity between cutting wood and a trash bag being ripped is approximately 0%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on available data, I would estimate that the percent similarity between cutting wood and waiting for epoxy to\n",
      "\n",
      "\n",
      "DATA: didnâ€™t know how to use lathe\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the two phrases, I estimate the percent similarity to be around 67%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn't find any information on the phrase \"didnâ€™t know how to use lathe\" being\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn't find any direct matches for the phrases \"didn't know how to use lathe\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the descriptions, I would estimate the percent similarity between \"didnâ€™t know how to use lat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the percent similarity, I'll use a simple method based on the number of words in the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the percent similarity, I'll use a simple method. \n",
      "\n",
      "First, I'll break down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the percent similarity, I'll compare the two phrases word by word.\n",
      "\n",
      "1. didnâ€™t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given phrases, I would estimate the percent similarity to be around 0%. They seem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the percent similarity, I'll compare the two phrases:\n",
      "\n",
      "1. \"didnâ€™t know how\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the percent similarity, I'll use a simple algorithm. \n",
      "\n",
      "After analyzing the two phrases,\n",
      "To calculate the percent similarity, I'll compare the two phrases.\n",
      "\n",
      "Here are the phrases with their individual\n"
     ]
    }
   ],
   "source": [
    "for i in range(2): \n",
    "    print(\"\\n\")\n",
    "    print(\"DATA: \" + testable_data[i] + \"\\n\")\n",
    "    for code in codes:\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": \"calculate the percent similarity between \" + testable_data[i] + \" and \" + code + \". Don't tell me how, just give me the percent similarity.\"}\n",
    "        ] \n",
    "        result = pipe(messages)\n",
    "        print(result[0][\"generated_text\"][1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52936aa0-4cf7-4da0-b8a9-ee5901770799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user',\n",
       "    'content': \"Pretend you are the world's best thematic analyst. Is there any similarity between 'Finding drill' and 'drill'? If so, tell me the percent similarity. Don't tell me how, just give me the percentage.\"},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"The similarity between 'Finding drill' and 'drill' is approximately 72%.\"}]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying a yes/no prompt\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Pretend you are the world's best thematic analyst. Is there any similarity between 'Finding drill' and 'drill'? If so, tell me the percent similarity. Don't tell me how, just give me the percentage.\"},\n",
    "]\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470fec4f-7414-40eb-9fdd-39491cf62dd2",
   "metadata": {},
   "source": [
    "**2.3) LLM: DeepSeek**\n",
    "- needs to be done from terminal\n",
    "- wait for HF to develop (LOL) or try vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4586cb1-be0f-4d7f-9331-e9675a736b1d",
   "metadata": {},
   "source": [
    "**3.1.1) text embedding: MPNet** (https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#semantic-search-models) \n",
    "- this is the pretrained model (general purpose), there are more on HF that might have more relevant training we can try\n",
    "- runs super quickly (yay!) (faster than other 2)\n",
    "- not the same as from the 2024 paper, might still contact the author for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29b77b0-b95f-455b-ac88-1152d0250236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "tensor([[1.0000, 0.6817, 0.0492],\n",
      "        [0.6817, 1.0000, 0.0421],\n",
      "        [0.0492, 0.0421, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "#full matrix to demo how text embedding works\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embeddings = model.encode([\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "])\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d439a7-a67d-4535-b9c6-8be5a66c73a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0868, 0.6279]])\n"
     ]
    }
   ],
   "source": [
    "#how it can be used as a coder\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "user_embeddings = model.encode(\"Loosening the lathe\") #user response\n",
    "code_embeddings = model.encode([\n",
    "    \"Someone squeezed through aisle and bumped user (bumped e-stop)\", #code\n",
    "    \"Lathe chuck overtightend\", #code\n",
    "])\n",
    "similarities = model.similarity(user_embeddings, code_embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63814ce-9c9a-45ce-9448-f085ee17b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import sys\n",
    "\n",
    "# Load https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "with open('output-MPNet.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    \n",
    "    for i in range(5): \n",
    "        print(\"\\n\")\n",
    "        print(\"DATA: \" + testable_data[i] + \"\\n\")\n",
    "        user_embeddings = model.encode(testable_data[i])\n",
    "        code_embeddings = model.encode(codes)\n",
    "        similarities = model.similarity(user_embeddings, code_embeddings)\n",
    "        results = similarities.tolist()\n",
    "        for i in range(len(codes)): \n",
    "            print(str(results[0][i]) + \"\\t\" + codes[i]) \n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387ab7a-dd36-40f6-824f-9d6e8bf33a22",
   "metadata": {},
   "source": [
    "**3.1.2) MPNet evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45784b72-b610-4c05-bf7c-b3d0efc5ed84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8', '1', '9', '10', '5', '1', '7', '8', '10', '5', '9', '7', '6', '10', '10', '5', '6', '6', '7', '10', '6', '1', '2', '7', '5', '1', '7', '9', '8', '4', '10', '10', '11', '5', '9', '1', '7', '5', '4', '9', '3', '7', '6', '2', '4', '5']\n",
      "['8', '0', '9', '10', '9', '1', '6', '8', '0', '5', '9', '7', '6', '0', '10', '5', '5', '6', '7', '10', '6', '1', '2', '7', '5', '1', '7', '9', '8', '4', '0', '10', '11', '5', '9', '6', '7', '5', '7', '9', '3', '7', '6', '2', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import sys\n",
    "\n",
    "# Load https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "predictions = []\n",
    " \n",
    "for i in range(len(testable_data)): \n",
    "    max_score = 0;\n",
    "    idx_of_max = 0;\n",
    "    user_embeddings = model.encode(testable_data[i])\n",
    "    code_embeddings = model.encode(codes)\n",
    "    similarities = model.similarity(user_embeddings, code_embeddings)\n",
    "    results = similarities.tolist()\n",
    "    for j in range(len(codes)): \n",
    "        #print(results)\n",
    "        if (results[0][j] > max_score):\n",
    "            idx_of_max = j+1\n",
    "            max_score = results[0][j]\n",
    "    predictions.append(idx_of_max)\n",
    "\n",
    "predictions_str = []\n",
    "for pred in predictions:\n",
    "    str_pred = str(pred)\n",
    "    predictions_str.append(str_pred)\n",
    "print((predictions_str))\n",
    "print((ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5b252a-e34a-41bb-b636-56d6ad20dec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 0 3 0]\n",
      " [0 3 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 6 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 4 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 6 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 5 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 4 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "[0.         0.75       0.72727273 1.         1.         1.\n",
      " 0.8        0.85714286 0.72727273 0.85714286 1.         0.90909091]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(confusion_matrix(ground_truths, predictions_str, labels=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\"]))\n",
    "MPNet_eval = f1_score(ground_truths, predictions_str, average=None)\n",
    "print(MPNet_eval)\n",
    "#check what we wanna do for the average parameter (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e0c5d-2df4-47a5-b240-5b1e5718a270",
   "metadata": {},
   "source": [
    "**3.2.1) Text embedding: Jina Embeddings V2** (https://huggingface.co/jinaai/jina-embeddings-v2-base-en?library=sentence-transformers)\n",
    "- same as in the physics ed paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3a5dd4-d905-4242-b52b-3cb2baad7acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81299573\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n",
    "model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
    "embeddings = model.encode(['Had to find a clamp', 'People forget to put away the clamps'])\n",
    "print(cos_sim(embeddings[0], embeddings[1]))\n",
    "#this is a better way to use the model :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9873b814-4d00-4894-bdd1-e353783438cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.8468, 0.6408],\n",
      "        [0.8468, 1.0000, 0.6417],\n",
      "        [0.6408, 0.6417, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "#exact same formatting as MPNet, but this is the auto-generated transformers code, see above for a better version\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"jinaai/jina-embeddings-v2-base-en\", trust_remote_code=True)\n",
    "\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614d041-8750-4422-9ec4-b3aac7930de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from transformers import AutoModel\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n",
    "model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
    "code_embeddings = model.encode(codes)\n",
    "\n",
    "results = []\n",
    "with open('output-JinaEmbeddingsV2.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    \n",
    "    for i in range(5): \n",
    "        print(\"\\n\")\n",
    "        print(\"DATA: \" + testable_data[i] + \"\\n\")\n",
    "        user_embeddings = model.encode(testable_data[i])\n",
    "        code_embeddings = model.encode(codes)\n",
    "        for k in range(len(codes)):\n",
    "            results.append(cos_sim(user_embeddings, code_embeddings[k]))\n",
    "        for i in range(len(codes)): \n",
    "            print(str(results[i]) + \"\\t\" + codes[i]) \n",
    "        results = []\n",
    "        \n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108a845-a785-4d70-967f-8c672ddd49a4",
   "metadata": {},
   "source": [
    "**3.1.2) Jina Embeddings V2 evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b458c37-8bda-4537-bd26-a993b72809d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8', '1', '9', '10', '5', '1', '6', '8', '10', '5', '9', '7', '6', '10', '10', '5', '5', '5', '7', '10', '6', '1', '2', '7', '5', '1', '7', '9', '10', '4', '10', '10', '11', '5', '9', '1', '7', '5', '5', '9', '9', '7', '6', '2', '4', '5']\n",
      "['8', '0', '9', '10', '9', '1', '6', '8', '0', '5', '9', '7', '6', '0', '10', '5', '5', '6', '7', '10', '6', '1', '2', '7', '5', '1', '7', '9', '8', '4', '0', '10', '11', '5', '9', '6', '7', '5', '7', '9', '3', '7', '6', '2', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from transformers import AutoModel\n",
    "from numpy.linalg import norm\n",
    "\n",
    "predictions = []\n",
    "cos_sim = lambda a,b: (a @ b.T) / (norm(a)*norm(b))\n",
    "model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
    "code_embeddings = model.encode(codes)\n",
    "\n",
    "results = []\n",
    "for i in range(len(testable_data)): \n",
    "    max_score = 0;\n",
    "    idx_of_max = 0;\n",
    "    user_embeddings = model.encode(testable_data[i])\n",
    "    for k in range(len(codes)):\n",
    "        results.append(cos_sim(user_embeddings, code_embeddings[k]))\n",
    "    for j in range(len(codes)): \n",
    "        #print(results)\n",
    "        if (results[j] > max_score):\n",
    "            idx_of_max = j+1\n",
    "            max_score = results[j]\n",
    "    predictions.append(idx_of_max)\n",
    "    results = []\n",
    "\n",
    "predictions_str = []\n",
    "for pred in predictions:\n",
    "    str_pred = str(pred)\n",
    "    predictions_str.append(str_pred)\n",
    "print((predictions_str))\n",
    "print((ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c09df6-b968-417c-a671-84b931c00b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 0 3 0]\n",
      " [0 3 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 7 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 1 4 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 6 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 5 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 4 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "[0.         0.75       0.66666667 1.         1.         0.\n",
      " 1.         0.82352941 0.8        0.92307692 0.8        0.83333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(confusion_matrix(ground_truths, predictions_str, labels=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\"]))\n",
    "JinaEmbeddingsV2_eval = f1_score(ground_truths, predictions_str, average=None)\n",
    "print(JinaEmbeddingsV2_eval)\n",
    "#check what we wanna do for the average parameter (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4505c5-b20f-4f21-8797-fa4d55091e96",
   "metadata": {},
   "source": [
    "**4) Formatting to compare evaluation results**\n",
    "- so far only comparing F1 scores for each code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363dc8d3-84fe-4f72-ae21-a3408b515dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eval-results.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    print(\"**The Code, followed by the F1 score for BART, then MPNet, then Jina Embeddings V2**\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    codes = [\"Lathe chuck overtightend\", \"18 V Drills too large to use with one hand\", \"Disposable gloves are a large size\", \"Miter saw is on tall table (awkward to use)\", \"People forget to put away the clamps\", \"Someone left sawdust and wood chips everywhere\", \"Someone squeezed through aisle and bumped user (bumped e-stop)\", \"Wood scraps too small to be useful\", \"Digging through the unlabeled cabinets looking for drill\", \"Trash bag is ripped\", \"Had to wait for epoxy to cure\"]\n",
    "    codes.insert(0, \"No code assigned\")\n",
    "    for i in range(len(codes)):\n",
    "        print(codes[i] + \"\\t\")\n",
    "        print(BART_eval[i])\n",
    "        print(\"\\t\")\n",
    "        print(MPNet_eval[i])\n",
    "        print(\"\\t\")\n",
    "        print(JinaEmbeddingsV2_eval[i])\n",
    "        print(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
